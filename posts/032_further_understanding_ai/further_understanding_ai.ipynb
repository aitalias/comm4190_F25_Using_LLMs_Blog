{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee1266e-0986-460f-9ef1-0bc16aa16799",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Further Understanding AI\"\n",
    "description: \"Thoughts at this point in the book\" \n",
    "author: \"Aitalia Sharpe\"\n",
    "date: \"11/21/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Living with a book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c51f4-b39c-4190-be82-f3c0f959d45b",
   "metadata": {},
   "source": [
    "![](ss_032_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ca47c-3bcc-4788-b7fb-5fb32962d7e0",
   "metadata": {},
   "source": [
    "**Current Thoughts:**\n",
    "\n",
    "So I've been making my way through Unmasking AI by Joy Buolamwini, and I just hit around page 150. What's really sticking with me from this section is how she breaks down the actual mechanics of how AI systems fail. But she doesn't do it in a boring, textbook way. Instead, she uses these really concrete examples that make you go \"oh wow, that's actually terrifying.\"\n",
    "\n",
    "One thing that jumped out at me is how she explains the whole training data problem. Basically, if you're building a facial recognition system and you only feed it photos of white dudes, it's going to be really good at recognizing white dudes and absolutely terrible at recognizing everyone else. She shows how this isn't just a small glitch, but it's baked into how these systems are designed from the ground up.\n",
    "\n",
    "What I appreciate is that she doesn't just point fingers and call it a day. She actually walks through how she discovered these failures in her own research. There's this moment where she's testing facial recognition software on herself, and the system straight-up doesn't detect her face until she puts on a white mask. That's the algorithm literally not seeing her as human until she makes herself look white. It's such a powerful image, and it really drives home how these supposedly \"objective\" systems are anything but.\n",
    "\n",
    "She also gets into the corporate side, discussing how companies rush these products to market without adequate testing across different demographics. The consequences are real: misidentifications, false arrests, and people being locked out of services they need. The stakes are incredibly high, especially for communities that are already over-policed and underserved.\n",
    "Overall, this section really solidified for me why this work matters. It's not just about making better algorithms; it's about questioning who builds them, how they're tested, and who pays the price when they fail.\n",
    "\n",
    "**Questions and Reflections**\n",
    "\n",
    "- **What specific technical concepts does the author explain, and how accessible are these explanations?**\n",
    "\n",
    "She breaks down concepts like training data bias and accuracy rates across demographics. The explanations are really accessible because she uses real-world examples instead of heavy jargon. Even without a computer science background, you can follow along.\n",
    "\n",
    "- **How does the author connect technical failures to broader social issues?**\n",
    "\n",
    "She consistently links algorithmic failures back to systemic racism and sexism. When facial recognition fails on darker-skinned faces, she connects it to historical patterns of who gets seen and valued in society.\n",
    "  \n",
    "- **What examples of algorithmic harm does she provide?**\n",
    "\n",
    "She talks about facial recognition misidentifying people, which can lead to wrongful arrests. She also discusses how these\n",
    "systems are deployed in ways that disproportionately affect marginalized communitiesâ€”especially in policing contexts.\n",
    "\n",
    "- **Does the author discuss the role of tech companies**\n",
    "\n",
    "How does she characterize their responsibility? Yes, she's critical of how tech companies prioritize speed and profit over thorough testing. She calls for these institutions to consider who might be harmed by their systems before rushing them to market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48d990-adb7-4c3a-9a6d-d267af3ba702",
   "metadata": {},
   "source": [
    "### I'm excited to finish the book and see what other criticisms of AI Buolamwini discusses!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
