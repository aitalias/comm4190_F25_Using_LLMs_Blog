{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b29167-c4fd-460c-89af-dff3e78320da",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Peeling Back The Layers\"\n",
    "description: \"Diving deeper into Joy Buolamwini's - Unmasking AI?\" \n",
    "author: \"Aitalia Sharpe\"\n",
    "date: \"10/15/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Living with a book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430f5a8-5905-4dfa-8942-7241f0ae2852",
   "metadata": {},
   "source": [
    "![](ss_031_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4da70-30cc-4e24-9eb3-1e513f85be27",
   "metadata": {},
   "source": [
    "### General Thoughts\n",
    "\n",
    "I'm about halfway through Joy Buolamwini's \"Unmasking AI,\" and things are starting to intensify. What's sticking with me from this section is how she breaks down the actual mechanics of how AI systems fail, and the fact that she's doing it in a way that makes the details fascinating to non-technical readers.\n",
    "\n",
    "One thing that stuck out to me was how she explained the whole training data problem. Basically, if you're building a facial recognition system and you only feed it one phenotype, it's going to be really good at recognizing people with those features and woefully unsuccessful with everyone else. She shows how this isn't just a small glitch, but the problem is baked into how these systems are designed.\n",
    "\n",
    "She also gets into the corporate side, discussing how companies rush these products to market without adequate testing across different demographics, producing consequences for users: misidentifications, false arrests, and people being locked out of services they need. The stakes are incredibly high, especially for minority communities that are already over-policed. Overall, this section really solidified the importance of this work.\n",
    "\n",
    "### Questions and Reflections:\n",
    "\n",
    "- How does she characterize the responsibility of tech companies for systematic failures?\n",
    "  \n",
    "She's critical of how tech companies prioritize speed and profit over thorough testing. She calls for these institutions to consider who might be harmed by their systems before rushing them to market.\n",
    "\n",
    "- What patterns am I noticing in how AI failures manifest?\n",
    "\n",
    "There's a clear pattern: the people who build AI systems often don't represent the diversity of people who will be affected by them. This leads to blind spots that become embedded in the technology itself. The failures aren't randomâ€”they consistently harm the same groups of people.\n",
    "\n",
    "**The book is building a compelling case that AI bias isn't a technical problem with a purely technical solution. It's a social justice issue that requires us to fundamentally rethink how we approach these technologies.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
