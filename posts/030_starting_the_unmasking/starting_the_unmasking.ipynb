{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7404a2b2-bd89-4c26-b2b5-b2e9f21a53f9",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Starting The Unmasking\"\n",
    "description: \"Early thoughts on Joy Buolamwini's - Unmasking AI?\" \n",
    "author: \"Aitalia Sharpe\"\n",
    "date: \"9/18/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Living with a book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdcf2d3-a1f1-42b7-be19-51bd864a11d8",
   "metadata": {},
   "source": [
    "![](ss_030_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2336f4-0fff-4c3b-977a-1d1286094601",
   "metadata": {},
   "source": [
    "### General Thoughts\n",
    "\n",
    "I'm about a quarter of the way through Joy Buolamwini's \"Unmasking AI,\" and I'm already finding her approach refreshingly different from prominent tech criticism. She's not delivering abstract warnings about AI; instead, she's showing us exactly how these systems work and how the failures directly affect real people.\n",
    "\n",
    "She opens, introducing readers to her background, where she describes moments where facial recognition technology simply didn't see her, literally failing to detect her face as a Black woman. These are her lived experiences as a researcher at MIT, not mere hypotheticals. Her personal stake in the matter drives the technical explanations deeper.\n",
    "\n",
    "What I appreciate most so far is her clarity. She's explaining complex concepts like machine learning and training data without dumbing them down, but also without losing readers who may not be tech-savvy. She's also starting to lay out the scope of the problem. She's showing that this bias is systematic, from the beginning of the data collection all the way through the end.\n",
    "\n",
    "\n",
    "### Questions and Reflections:\n",
    "- What is Buolamwini's main argument so far?\n",
    "\n",
    "She seems to be building toward the idea that AI systems reflect existing inequalities. It's not that the technology is neutral and gets misused; the bias is baked in from the start. It functions based on who builds these systems, what data they're trained on, and who benefits from them being used.\n",
    "\n",
    "- What questions am I left with at this point?\n",
    "\n",
    "So far, she's identifying problems, which is important, but I'm wondering what she thinks should actually change. Is this about better regulation? Different approaches to building AI? I'm hoping the book addresses these questions as it progresses.\n",
    "\n",
    "**The personal narrative approach makes abstract technical failures feel urgent and real. I'm looking forward to seeing where she takes this argument.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
